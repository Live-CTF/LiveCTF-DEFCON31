use std::sync::Arc;

use backon::ConstantBuilder;
use backon::Retryable;
use celery::prelude::*;
use celery::Celery;
use celery::CeleryBuilder;
use diesel::prelude::*;
use diesel::r2d2;
use diesel::PgConnection;
use lazy_static::lazy_static;
use log::{info, warn};
use nix::sys::signal::{self, Signal};
use nix::unistd::Pid;
use std::time::Duration;
use tokio::task;
use uuid::Uuid;

use object_store::ObjectStore;

use common::models::{Exploit, ExploitStatus};

const BUILD_MEMORY: &str = "2g";
const BUILD_CPU: f32 = 1.0;
const BUILD_DISK: &str = "20g";
const BUILD_MAX_SECONDS: u64 = 120;

// TODO (P2): Remove this cursed global variable hack once celery-rs supports passing extra data
//       https://github.com/rusty-celery/rusty-celery/issues/152
lazy_static! {
    static ref DB_POOL: r2d2::Pool<r2d2::ConnectionManager<PgConnection>> =
        common::setup_database_pool().expect("Failed to connect to database");
}
lazy_static! {
    static ref OBJECT_STORE: Arc<dyn ObjectStore> =
        common::get_object_store().expect("Failed to setup object store");
}
lazy_static! {
    static ref BUILD_PATH: String = std::env::var("BUILD_PATH").expect("BUILD_PATH not set");
}
lazy_static! {
    static ref EXPLOIT_DOCKER_REPO: String =
        std::env::var("EXPLOIT_DOCKER_REPO").expect("EXPLOIT_DOCKER_REPO not set");
}
lazy_static! {
    static ref CONTAINER_RUNNER: String =
        std::env::var("CONTAINER_RUNNER").expect("CONTAINER_RUNNER not set");
}
lazy_static! {
    static ref DISK_LIMIT_AVAILABLE: bool = std::env::var("DISK_LIMIT_AVAILABLE").is_ok();
}

async fn connect_celery() -> Result<Arc<Celery>, CeleryError> {
    let celery = CeleryBuilder::new(
        "celery",
        &std::env::var("AMQP_ADDR").expect("AMQP_ADDR not set"),
    )
    .task_route("run_exploit", "run")
    .default_queue("build")
    .task_retry_for_unexpected(true)
    .prefetch_count(
        num_cpus::get()
            .try_into()
            .expect("Could not convert number of CPUs to u16"),
    )
    .acks_late(true)
    .build()
    .await?;

    celery.register_task::<build_exploit>().await?;

    Ok(Arc::new(celery))
}

pub async fn configure_celery_builder() -> Result<Arc<Celery>, CeleryError> {
    let backon_settings = ConstantBuilder::default()
        .with_delay(Duration::from_secs(5))
        .with_max_times(12);
    connect_celery
        .retry(&backon_settings)
        .notify(|err: &CeleryError, dur: Duration| {
            log::info!(
                "Retrying connection to Celery in {:?}, error {:?}",
                dur,
                err
            );
        })
        .await
}

fn fetch_exploit(exploit_uuid: Uuid) -> TaskResult<Exploit> {
    use common::schema::exploits::dsl::*;
    let mut conn = DB_POOL
        .get()
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
    match exploits
        .filter(exploit_id.eq(exploit_uuid))
        .first::<Exploit>(&mut conn)
        .optional()
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?
    {
        Some(exploit) => Ok(exploit),
        None => Err(TaskError::UnexpectedError(format!(
            "Unable to find exploit with id {exploit_uuid}"
        ))),
    }
}

fn update_exploit_building(exploit: &Exploit) -> TaskResult<()> {
    use common::schema::exploits::dsl::*;
    let mut conn = DB_POOL
        .get()
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
    diesel::update(&exploit)
        .set(status.eq(ExploitStatus::Building))
        .execute(&mut conn)
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
    Ok(())
}

fn update_exploit_built(exploit: &Exploit, build_success: bool) -> TaskResult<()> {
    use common::schema::exploits::dsl::*;
    let mut conn = DB_POOL
        .get()
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;

    let update = diesel::update(&exploit);
    let update = if build_success {
        update.set((status.eq(ExploitStatus::BuildOk), pending.eq(Some(true))))
    } else {
        update.set((
            status.eq(ExploitStatus::BuildFailed),
            pending.eq(None::<bool>),
        ))
    };
    update
        .execute(&mut conn)
        .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
    Ok(())
}

async fn do_build_exploit_kaniko(exploit: &Exploit) -> TaskResult<bool> {
    let image_tag = &format!(
        "{}{}:latest",
        EXPLOIT_DOCKER_REPO.as_str(),
        exploit.archive_id()
    );
    let archive_path = object_store::path::Path::from(format!("{}.tar.gz", exploit.archive_id()));
    let exploit_archive_meta = OBJECT_STORE.head(&archive_path).await.map_err(|err| {
        TaskError::UnexpectedError(format!(
            "Exploit {}, Failed to retrieve exploit metadata: {}",
            exploit.exploit_id(),
            err
        ))
    })?;

    let context_url = format!(
        "{}{}",
        common::get_object_store_url_prefix().map_err(|err| {
            TaskError::UnexpectedError(format!(
                "Exploit {}, failed to get exploit context URL: {}",
                exploit.exploit_id(),
                err
            ))
        })?,
        exploit_archive_meta.location
    );
    println!("Location: {context_url}");

    let mut exploit_build_command = async_process::Command::new(&*CONTAINER_RUNNER);

    exploit_build_command.args([
        "run",
        "--init",
        "--rm",
        &format!("--cpus={BUILD_CPU}"),
        &format!("--memory={BUILD_MEMORY}"),
        "-e",
        "GOOGLE_APPLICATION_CREDENTIALS=/credentials/gcp.json",
        "-v",
        "livectf_credentials:/credentials:ro",
    ]);

    if *DISK_LIMIT_AVAILABLE {
        exploit_build_command.args(["--storage-opt", &format!("size={BUILD_DISK}")]);
    } else {
        log::warn!("Not limiting available disk space for exploit build container");
    }

    exploit_build_command.args([
        "gcr.io/kaniko-project/executor:latest",
        "--destination",
        image_tag,
        "--insecure-registry",
        EXPLOIT_DOCKER_REPO.as_str(),
        "--cache=true",
        "--context",
        context_url.as_ref(),
    ]);

    let mut exploit_build = exploit_build_command.spawn().map_err(|err| {
        TaskError::UnexpectedError(format!(
            "Exploit {}, failed to spawn Kaniko: {}",
            exploit.exploit_id(),
            err
        ))
    })?;

    let build_status = match tokio::time::timeout(
        Duration::from_secs(BUILD_MAX_SECONDS),
        exploit_build.status(),
    )
    .await
    {
        Err(err) => {
            match exploit_build.id().try_into() {
                Err(_) => {
                    log::warn!(
                        "Exploit {}, build time limit exceeded: {}, failed to get process pid",
                        exploit.exploit_id(),
                        err
                    );
                }
                Ok(pid) => {
                    match signal::kill(Pid::from_raw(pid), Signal::SIGTERM) {
                        Ok(()) => {
                            log::info!(
                                "Exploit {}, build time limit exceeded: {}",
                                exploit.exploit_id(),
                                err
                            );
                        }
                        Err(_) => {
                            log::warn!(
                                "Exploit {}, build time limit exceeded: {}, failed to kill process",
                                exploit.exploit_id(),
                                err
                            );
                        }
                    };
                }
            };

            false
        }
        Ok(exploit_build_res) => exploit_build_res
            .map_err(|err| {
                TaskError::UnexpectedError(format!(
                    "Exploit {}, failed to get exit status for Kaniko: {}",
                    exploit.exploit_id(),
                    err
                ))
            })?
            .success(),
    };

    Ok(build_status)
}

#[celery::task]
pub async fn build_exploit(exploit_uuid: Uuid) -> TaskResult<()> {
    info!("Build requested for exploit {}", exploit_uuid);

    let exploit_to_build = fetch_exploit(exploit_uuid)?;
    if *exploit_to_build.status() == ExploitStatus::Cancelled {
        info!("Exploit with id {} cancelled, skipping build", exploit_uuid);
        return Ok(());
    }

    if *exploit_to_build.status() == ExploitStatus::BuildFailed {
        warn!(
            "Exploit with id {} already failed to build, not retrying",
            exploit_uuid
        );
        return Ok(());
    }

    info!("Going to build exploit {}", exploit_uuid);

    let new_build_status = if *exploit_to_build.status() == ExploitStatus::BuildOk {
        warn!(
            "Exploit with id {} already built, resubmitting to run queue",
            exploit_to_build.exploit_id()
        );
        true
    } else {
        update_exploit_building(&exploit_to_build)?;
        let build_status =
            task::block_in_place(|| do_build_exploit_kaniko(&exploit_to_build)).await?;
        update_exploit_built(&exploit_to_build, build_status)?;
        build_status
    };

    if new_build_status {
        let queue = configure_celery_builder()
            .await
            .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
        queue
            .send_task(exploit_runner::run_exploit::new(exploit_uuid))
            .await
            .map_err(|err| TaskError::UnexpectedError(err.to_string()))?;
    }

    Ok(())
}
